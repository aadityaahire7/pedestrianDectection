{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaditya Ahire\\AppData\\Local\\Temp\\ipykernel_20980\\3355540971.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aaditya Ahire\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aaditya Ahire\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aaditya Ahire\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aaditya Ahire\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 198, 198, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 99, 99, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 97, 97, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 48, 48, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 270848)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               34668672  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34781506 (132.68 MB)\n",
      "Trainable params: 34781506 (132.68 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\Aaditya Ahire\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aaditya Ahire\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "30/30 [==============================] - 61s 2s/step - loss: 1.7036 - accuracy: 0.5456 - val_loss: 0.6912 - val_accuracy: 0.5149\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 50s 2s/step - loss: 0.6873 - accuracy: 0.5752 - val_loss: 0.7097 - val_accuracy: 0.5106\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 45s 2s/step - loss: 0.6355 - accuracy: 0.6292 - val_loss: 0.7729 - val_accuracy: 0.5787\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 46s 2s/step - loss: 0.6285 - accuracy: 0.6610 - val_loss: 0.5829 - val_accuracy: 0.6936\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 47s 2s/step - loss: 0.5056 - accuracy: 0.7574 - val_loss: 0.6279 - val_accuracy: 0.6340\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 47s 2s/step - loss: 0.3848 - accuracy: 0.8157 - val_loss: 1.0955 - val_accuracy: 0.6383\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 45s 1s/step - loss: 0.3044 - accuracy: 0.8591 - val_loss: 0.9668 - val_accuracy: 0.6766\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 45s 1s/step - loss: 0.1870 - accuracy: 0.9343 - val_loss: 0.9832 - val_accuracy: 0.6383\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 45s 2s/step - loss: 0.0818 - accuracy: 0.9735 - val_loss: 1.2693 - val_accuracy: 0.6681\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 45s 2s/step - loss: 0.0295 - accuracy: 0.9947 - val_loss: 1.9159 - val_accuracy: 0.6553\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 45s 2s/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 1.8666 - val_accuracy: 0.6596\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 46s 2s/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 2.1338 - val_accuracy: 0.6383\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 45s 2s/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 1.9789 - val_accuracy: 0.6638\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 45s 1s/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 1.9433 - val_accuracy: 0.6723\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 45s 1s/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 2.2811 - val_accuracy: 0.6468\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 45s 2s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1101 - val_accuracy: 0.6809\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 45s 1s/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 2.1152 - val_accuracy: 0.6723\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 45s 2s/step - loss: 0.0047 - accuracy: 0.9979 - val_loss: 2.1278 - val_accuracy: 0.6766\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 46s 2s/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 2.0413 - val_accuracy: 0.6894\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 49s 2s/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 2.1239 - val_accuracy: 0.6723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaditya Ahire\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import os\n",
    "from xml.etree import ElementTree\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "keras = tf.keras\n",
    "class_names = ['person','person-like']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "n_classes = 2\n",
    "size = (200,200)\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from xml.etree import ElementTree\n",
    "def load_data():\n",
    "    datasets = [\n",
    "    \"C:\\\\Users\\\\Aaditya Ahire\\\\Desktop\\\\sem6\\\\nullclass\\\\pedestrianDetection\\\\pedestrainDetect\\\\dataset\\\\Train\\\\Train\",\n",
    "    \"C:\\\\Users\\\\Aaditya Ahire\\\\Desktop\\\\sem6\\\\nullclass\\\\pedestrianDetection\\\\pedestrainDetect\\\\dataset\\\\Test\\\\Test\",\n",
    "    \"C:\\\\Users\\\\Aaditya Ahire\\\\Desktop\\\\sem6\\\\nullclass\\\\pedestrianDetection\\\\pedestrainDetect\\\\dataset\\\\Val\\\\Val\"\n",
    "]\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for dataset in datasets:\n",
    "        imags = []\n",
    "        labels = []\n",
    "        directoryA = os.path.join(dataset, 'Annotations')\n",
    "        directoryIMG = os.path.join(dataset, 'JPEGImages')\n",
    "        file = os.listdir(directoryA)\n",
    "        img = os.listdir(directoryIMG)\n",
    "        file.sort()\n",
    "        img.sort()\n",
    "\n",
    "        i = 0\n",
    "        for xml in file:\n",
    "            xmlf = os.path.join(directoryA, xml)\n",
    "            dom = ElementTree.parse(xmlf)\n",
    "            vb = dom.findall('object')\n",
    "            label = vb[0].find('name').text\n",
    "            labels.append(class_names_label[label])\n",
    "\n",
    "            img_path = os.path.join(directoryIMG, img[i])\n",
    "            curr_img = cv2.imread(img_path)\n",
    "            # Assuming 'size' is defined somewhere in your code\n",
    "            curr_img = cv2.resize(curr_img, size)\n",
    "            imags.append(curr_img)\n",
    "            i += 1\n",
    "        \n",
    "        imags = np.array(imags, dtype='float32')\n",
    "        imags = imags / 255\n",
    "        \n",
    "        labels = np.array(labels, dtype='int32')\n",
    "\n",
    "        output.append((imags, labels))\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "(train_images, train_labels),(test_images, test_labels),(val_images, val_labels) = load_data()\n",
    "train_images.shape\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Assume you have already loaded and preprocessed train_images, train_labels, test_images, and test_labels\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(200, 200, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=20, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Save the model\n",
    "model.save(\"action.h5\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the saved model\n",
    "loaded_model = models.load_model(\"action.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.9989\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = history.history['accuracy'][-1]\n",
    "print(f\"Final Accuracy: {train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 132ms/step\n",
      "Pedestrian detected.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import models\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = models.load_model(\"action.h5\")\n",
    "\n",
    "# Input an image from PC\n",
    "input_image_path = \"image_test.jpeg\"\n",
    "input_image = cv2.imread(input_image_path)\n",
    "size = (200, 200)\n",
    "input_image_resized = cv2.resize(input_image, size)\n",
    "input_image_normalized = input_image_resized / 255.0\n",
    "input_image_expanded = np.expand_dims(input_image_normalized, axis=0)\n",
    "\n",
    "# Make Predictions\n",
    "predictions = loaded_model.predict(input_image_expanded)\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "predicted_class = class_names[predicted_class_index]\n",
    "\n",
    "# Display output message\n",
    "if predicted_class == 'person':\n",
    "    print(\"Pedestrian detected.\")\n",
    "else:\n",
    "    print(\"No pedestrian detected.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class PedestrianDetectorGUI:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "        # Initialize Tkinter window with a larger size\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Pedestrian Detector\")\n",
    "        self.root.geometry(\"400x400\")  # Set the initial window size\n",
    "\n",
    "        # Create and configure the main frame\n",
    "        self.main_frame = tk.Frame(self.root, bg='#F0F0F0')  # Set background color\n",
    "        self.main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Create labels for displaying image and predicted class\n",
    "        self.image_label = tk.Label(self.main_frame, bg='#FFFFFF', relief=tk.SOLID, borderwidth=2)\n",
    "        self.image_label.pack(pady=10)\n",
    "\n",
    "        self.predicted_class_label = tk.Label(self.main_frame, text=\"Predicted Class: \", font=(\"Helvetica\", 12), bg='#F0F0F0')\n",
    "        self.predicted_class_label.pack(pady=5)\n",
    "\n",
    "        # Create a button to load an image\n",
    "        self.load_button = tk.Button(self.main_frame, text=\"Load Image\", command=self.load_image, relief=tk.RAISED, borderwidth=2)\n",
    "        self.load_button.pack(pady=10)\n",
    "\n",
    "        # Run the Tkinter main loop\n",
    "        self.root.mainloop()\n",
    "\n",
    "    def load_image(self):\n",
    "        # Open a file dialog to select an image file\n",
    "        file_path = filedialog.askopenfilename()\n",
    "\n",
    "        if file_path:\n",
    "            # Load and preprocess the selected image\n",
    "            input_image = cv2.imread(file_path)\n",
    "            input_image_resized = cv2.resize(input_image, size)\n",
    "            input_image_normalized = input_image_resized / 255.0\n",
    "            input_image_expanded = np.expand_dims(input_image_normalized, axis=0)\n",
    "\n",
    "            # Make predictions\n",
    "            predictions = self.model.predict(input_image_expanded)\n",
    "            predicted_class_index = np.argmax(predictions)\n",
    "            predicted_class = class_names[predicted_class_index]\n",
    "\n",
    "            # Display the input image\n",
    "            self.display_image(input_image)\n",
    "\n",
    "            # Update the predicted class label\n",
    "            self.predicted_class_label.config(text=f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "            # Show detection result directly on the GUI window\n",
    "            if predicted_class == 'person':\n",
    "                \n",
    "                detection_result = \"Pedestrian detected!\" \n",
    "            else:\n",
    "                detection_result=\"No pedestrian detected.\"\n",
    "            self.display_detection_result(detection_result)\n",
    "\n",
    "    def display_image(self, image):\n",
    "        # Convert the image to RGB format\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Convert the image to a PhotoImage object\n",
    "        image_tk = ImageTk.PhotoImage(Image.fromarray(image_rgb))\n",
    "\n",
    "        # Update the image label\n",
    "        self.image_label.config(image=image_tk)\n",
    "        self.image_label.image = image_tk  # Keep a reference to avoid garbage collection issues\n",
    "\n",
    "    def display_detection_result(self, result):\n",
    "        # Update the GUI window with the detection result\n",
    "        result_label = tk.Label(self.main_frame, text=result, font=(\"Helvetica\", 14, \"bold\"), fg='#228B22' if \"Pedestrian\" in result else '#FF0000', bg='#F0F0F0')\n",
    "        result_label.pack(pady=10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create an instance of the PedestrianDetectorGUI class and pass the loaded model\n",
    "    gui = PedestrianDetectorGUI(loaded_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
